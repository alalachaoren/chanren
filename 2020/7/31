今天把昨天那篇论文看完了，然后发现其实他们做分类的话，存下来置信度比较高的一些数据，用来比较这些数据的分布和下一个时间段的数据的分布，
但是如果在我这个模型中的话，我每个阶段其实存下来的都是正常的一些数据，然而这些没有存的异常数据也会影响这个前后分布的相似分计算，
如果这样的话，用KL散度这种计算分布之间距离的话就不是很好了，就想着用之前那个概念飘逸检测器，就是将上一个时间段数据给标签1，下一个时间段数据给标签0，
然后通过一个简单的分类器分类，计算auc分数，虽然这样的话也可能会有因为没有异常数据带来的影响，但是多做几次算个平均或许会减小误差吧，
