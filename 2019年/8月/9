今天看了论文中论述到的自己的FPPDL（Fog-embedded privacy-preserving deep learning）框架，在其中，通过随机映射来保证安全和差分隐私来提供隐私保护，
其中关于差分隐私的技术涉及到了一小部分，不是很懂就找时间问了一下杜磊，了解了大概的意思。
在框架中雾节点相互独立，并发训练模型，并在每个时间点上选择一部分计算的梯度，再根据FPPDL中的‘最大值’标准上传到云中，以及通过异步更新参数的随机性，
即其中一个雾节点在训练一组数据的时候，其他节点可能在训练结束之前更新这些数据来提高深度学习神经网络精度。
在实验中通过改变雾节点数量来训练相同数目的数据、改变每个雾节点下的底层节点数目、端点之间的非独立并行分布数据分区、投影尺寸、以及容错率几个方面来与
中心框架和独立框架所训练的数据进行对比。总体实验结果所需的通信成本大大减少,而隐私和准确性同时得到了保障。
看完这篇论文之后让我对边缘计算、深度学习、以及隐私保护和论文的整体框架有了更深一步的了解。
